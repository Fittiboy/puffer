{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e26a86c3-4dbf-48e7-bf82-91a9d1742091",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fitti/.conda/envs/puffer/lib/python3.11/site-packages/gymnasium/envs/registration.py:596: UserWarning: \u001b[33mWARN: plugin: shimmy.registration:register_gymnasium_envs raised Traceback (most recent call last):\n",
      "  File \"/home/fitti/.conda/envs/puffer/lib/python3.11/site-packages/gymnasium/envs/registration.py\", line 594, in load_plugin_envs\n",
      "    fn()\n",
      "  File \"/home/fitti/.conda/envs/puffer/lib/python3.11/site-packages/shimmy/registration.py\", line 304, in register_gymnasium_envs\n",
      "    _register_atari_envs()\n",
      "  File \"/home/fitti/.conda/envs/puffer/lib/python3.11/site-packages/shimmy/registration.py\", line 205, in _register_atari_envs\n",
      "    import ale_py\n",
      "  File \"/home/fitti/.conda/envs/puffer/lib/python3.11/site-packages/ale_py/__init__.py\", line 66, in <module>\n",
      "    register_v0_v4_envs()\n",
      "  File \"/home/fitti/.conda/envs/puffer/lib/python3.11/site-packages/ale_py/registration.py\", line 176, in register_v0_v4_envs\n",
      "    _register_rom_configs(legacy_games, obs_types, versions)\n",
      "  File \"/home/fitti/.conda/envs/puffer/lib/python3.11/site-packages/ale_py/registration.py\", line 62, in _register_rom_configs\n",
      "    gymnasium.register(\n",
      "    ^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: partially initialized module 'gymnasium' has no attribute 'register' (most likely due to a circular import)\n",
      "\u001b[0m\n",
      "  logger.warn(f\"plugin: {plugin.value} raised {traceback.format_exc()}\")\n"
     ]
    }
   ],
   "source": [
    "from einops import rearrange\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import ale_py\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "from math import prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "215f2b36-862b-47b4-85c3-f2e7d7f97229",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7fb39da-d5bc-4ece-9fac-61b81affe120",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.9.0+750d7f9)\n",
      "[Powered by Stella]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"ALE/Breakout-v5\")\n",
    "env = gym.wrappers.TransformObservation(env, lambda x: rearrange(x, \"h w c -> c h w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "841f7e7d-32b6-4339-af17-15daa43f9f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 210, 160), 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ob_shape, n_actions = env.observation_space.shape, env.action_space.n\n",
    "ob_shape = (ob_shape[2], ob_shape[0], ob_shape[1])\n",
    "ob_shape, n_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7308fd94-a689-4f75-8ec6-867aa28d7ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, first_channels, second_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, first_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(first_channels, second_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(second_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "007b9492-a210-4497-b4ca-0ef1e0198093",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, first_channels, second_channels, out_channels, out_size=None):\n",
    "        super().__init__()\n",
    "        if out_size:\n",
    "            upsampler = nn.UpsamplingBilinear2d(size=out_size)\n",
    "        else:\n",
    "            upsampler = nn.UpsamplingBilinear2d(scale_factor=2)\n",
    "        self.decoder = nn.Sequential(\n",
    "            upsampler,\n",
    "            nn.Conv2d(in_channels, first_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(first_channels, second_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(second_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a4365c8-159b-4352-8b3b-0ae3bc618183",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, ob_shape):\n",
    "        super().__init__()\n",
    "        c, h, w = ob_shape\n",
    "        self.encoder = nn.Sequential(\n",
    "            EncoderBlock(c, 16, 32, 32),\n",
    "            EncoderBlock(32, 48, 48, 64),\n",
    "            EncoderBlock(64, 128, 128, 64),\n",
    "            EncoderBlock(64, 48, 32, 32),\n",
    "        )\n",
    "\n",
    "        dummy_in = torch.zeros((1,) + tuple(ob_shape))\n",
    "        self.out_shape = self.encoder(dummy_in).shape[1:]\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a606a822-bae4-42c0-af32-51e7243ed463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 13, 10])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = Encoder(ob_shape)\n",
    "enc.out_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0c06869-b3bc-4733-acc1-9da89bb28ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, ob_shape):\n",
    "        super().__init__()\n",
    "        c, h, w = ob_shape\n",
    "        self.decoder = nn.Sequential(\n",
    "            DecoderBlock(32, 32, 48, 64),\n",
    "            DecoderBlock(64, 32, 16, c, out_size=[h, w]),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d098e9f-b394-4434-8a31-638b175b8de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentNetwork(nn.Module):\n",
    "    def __init__(self, in_shape, n_hiddens):\n",
    "        super().__init__()\n",
    "        self.input = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(prod(in_shape), n_hiddens),\n",
    "        )\n",
    "        self.step = nn.Linear(n_hiddens, n_hiddens)\n",
    "\n",
    "    def init_state(self):\n",
    "        return torch.zeros(n_hiddens, dtype=torch.float32)\n",
    "        \n",
    "    def forward(self, x, state):\n",
    "        state = self.step(state) + self.input(x)\n",
    "\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c18059b5-73ee-4e48-8365-b59a520b64a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self, n_hiddens, n_actions):\n",
    "        super().__init__()\n",
    "        self.head = nn.Linear(n_hiddens, n_actions)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b651ec76-9ccb-45d4-9cb2-26d9b1f81776",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueNetwork(nn.Module):\n",
    "    def __init__(self, n_hiddens):\n",
    "        super().__init__()\n",
    "        self.head = nn.Linear(n_hiddens, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c4d6034-ce52-45d4-b9fd-7d28fab31574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b12c0c99-c683-4505-9a65-c3816f0a3d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(logits):\n",
    "    dist = torch.distributions.Categorical(logits=logits) # shape [batch_size, n_actions]\n",
    "    \n",
    "    action = dist.sample() # Shape: [n_actions]\n",
    "    log_prob = dist.log_prob(action)\n",
    "\n",
    "    return action, log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "250b035a-d545-4134-9e4e-6309f724d699",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hiddens = 128\n",
    "gamma = 0.99\n",
    "val_lr = 1e-4\n",
    "pol_lr = 1e-4\n",
    "\n",
    "encoder = Encoder(ob_shape).to(device=device)\n",
    "#decoder = Decoder(ob_shape).to(device=device)\n",
    "rec_net = RecurrentNetwork(encoder.out_shape, n_hiddens).to(device=device)\n",
    "pol_net = PolicyNetwork(n_hiddens, n_actions).to(device=device)\n",
    "val_net = ValueNetwork(n_hiddens).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "324e62fb-4dd0-4b9d-809b-983f8eb1f944",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss_fn = nn.MSELoss()\n",
    "\n",
    "val_optimizer = optim.Adam(val_net.parameters(), lr=val_lr)\n",
    "pol_optimizer = optim.Adam(pol_net.parameters(), lr=pol_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78e08eb5-398b-4035-8559-edfd4fb79e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 275 Best return: 7.0\t\t"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 43\u001b[0m\n\u001b[1;32m     41\u001b[0m val_optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     42\u001b[0m pol_optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 43\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m val_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     45\u001b[0m pol_optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.conda/envs/puffer/lib/python3.11/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/puffer/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/puffer/lib/python3.11/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ob, _ = env.reset()\n",
    "ob = torch.from_numpy(ob).to(device=device, dtype=torch.float32, non_blocking=True).unsqueeze(0)\n",
    "state = rec_net.init_state().to(device=device)\n",
    "\n",
    "ret = 0\n",
    "best_ret = 0\n",
    "episodes = 0\n",
    "while True:\n",
    "    latent = encoder(ob)\n",
    "    state = rec_net(latent, state.detach())\n",
    "    logits = pol_net(state)\n",
    "    value = val_net(state)\n",
    "    \n",
    "    action, log_prob = select_action(logits)\n",
    "    \n",
    "    next_ob, reward, done, truncated, _ = env.step(action)\n",
    "    next_ob = torch.from_numpy(next_ob).to(device=device, dtype=torch.float32, non_blocking=True).unsqueeze(0)\n",
    "    ret += reward\n",
    "\n",
    "    if done or truncated:\n",
    "        episodes += 1\n",
    "        if ret > best_ret:\n",
    "            best_ret = ret\n",
    "        print(\"Episode\", episodes, \"Best return:\", best_ret, end=\"\\t\\t\\r\")\n",
    "        ret = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        next_latent = encoder(next_ob)\n",
    "        next_state = rec_net(latent, state)\n",
    "        next_value = val_net(state)\n",
    "        \n",
    "    td_target = reward + gamma * next_value * ~(done | truncated)\n",
    "    with torch.no_grad():\n",
    "        advantage = (td_target - value)\n",
    "    \n",
    "    val_loss = val_loss_fn(td_target, value)\n",
    "    pol_loss = -log_prob * advantage\n",
    "\n",
    "    loss = val_loss + pol_loss\n",
    "\n",
    "    val_optimizer.zero_grad()\n",
    "    pol_optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    val_optimizer.step()\n",
    "    pol_optimizer.step()\n",
    "\n",
    "    if done or truncated:\n",
    "        next_ob, _ = env.reset()\n",
    "        next_ob = torch.from_numpy(next_ob).to(device=device, dtype=torch.float32, non_blocking=True).unsqueeze(0)\n",
    "    ob = next_ob"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
