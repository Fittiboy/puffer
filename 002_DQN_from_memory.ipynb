{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac02b509-a063-4b90-bc97-070fa55a4fad",
   "metadata": {},
   "source": [
    "# DQN from Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6f71e5-06fd-4076-b17b-7c5dfbcec29c",
   "metadata": {},
   "source": [
    "I need:\n",
    "* [x] The actual Q network\n",
    "* [x] A replay buffer\n",
    "* [x] Action selection\n",
    "* [x] Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d305b5f-f764-4f31-8136-f8d74b422982",
   "metadata": {},
   "source": [
    "The process:\n",
    "1. Set up online Q network and target network\n",
    "1. Initialize (vectorized) environment\n",
    "1. Perform training loop (Optional: With logging)\n",
    "1. Evalute and record an episode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55eaf9b0-3d67-4300-ab9e-961ff304637d",
   "metadata": {},
   "source": [
    "## The Q network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b41c807d-614e-4b2e-a9a7-57c3ef306b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40fc4ef5-46a3-49a8-bea5-fbb5e17f4f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, obs_shape, n_actions, n_hiddens=128):\n",
    "        super().__init__()\n",
    "        # The observations are Batch x width x stack (channels) x height, for some reason\n",
    "        in_shape = (obs_shape[0], obs_shape[2], obs_shape[3], obs_shape[1])\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.convs = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_shape[1], out_channels=16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 32, 3, padding=1),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "\n",
    "        # Calculate the input size for the first fully connected layer\n",
    "        dummy_in = torch.zeros(*in_shape[1:])\n",
    "        dummy_out = self.convs(dummy_in)\n",
    "        n_input = dummy_out.shape.numel()\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(n_input, n_hiddens),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hiddens, n_actions),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = next(self.mlp.parameters())[0].device\n",
    "        x = torch.tensor(np.array(x) / 255.0, dtype=torch.float32, device=device)\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        \n",
    "        x = self.convs(x)\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe48ec66-c92d-4227-8656-0254cd978ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PufferQNetwork(nn.Module):\n",
    "    def __init__(self, n_input, n_actions, n_hiddens=128):\n",
    "        super().__init__()\n",
    "        # Fully connected layers\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(n_input, n_hiddens),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hiddens, n_actions),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tensor(np.array(x), dtype=torch.float32, device=device)\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b43d0d-9380-4e9d-b853-68cb75eb4c7e",
   "metadata": {},
   "source": [
    "## Replay Buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe666c1-9b1b-42a5-8492-fb7733c1d7e6",
   "metadata": {},
   "source": [
    "* Needs to be able to store some number of transitions\n",
    "* Needs to automatically kick out old transitions\n",
    "* Needs `store`\n",
    "* Needs `extend`\n",
    "* Needs `__len__()`\n",
    "* Neesd `sample()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba5c4b66-3b51-4e3f-a8a0-d4fa14d91e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e208182-c144-44c0-927a-fdd0dac4331b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity: int):\n",
    "        self.capacity = capacity\n",
    "        self.queue = deque(maxlen=capacity)\n",
    "\n",
    "    def store(self, transition):\n",
    "        self.queue.append(transition)\n",
    "\n",
    "    def extend(self, transitions):\n",
    "        for transition in transitions:\n",
    "            self.store(transition)\n",
    "\n",
    "    def sample(self, n_samples: int):\n",
    "        return [random.choice(self.queue) for _ in range(n_samples)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.queue)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.queue.__repr__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f559d473-fb8b-40fd-a502-6c1d2cfe8682",
   "metadata": {},
   "source": [
    "## Action Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7baf269-b5c7-4871-9d4c-91c4d50684d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_actions(q_values, epsilon):\n",
    "    batch_size, n_actions = q_values.shape\n",
    "    if random.random() < epsilon:\n",
    "        return torch.randint(0, n_actions, [batch_size])\n",
    "    return torch.argmax(q_values, dim=1).cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475041b7-50b1-4881-90c7-bb97ec5f4852",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22278c0c-a165-448f-92dc-ea1a24931ccb",
   "metadata": {},
   "source": [
    "1. [x] Initialize replay buffer\n",
    "1. [x] Reset `env`\n",
    "1. [x] Initialize `returns` array\n",
    "1. [x] Initialize `episodes` counter\n",
    "1. [x] For `n_steps`\n",
    "    1. [x] Take step in environment\n",
    "    1. [x] (Optional) Add `rewards` to `returns` array\n",
    "    1. [x] (Optional) Add `np.sum(dones | truncateds)` to episodes\n",
    "    1. [x] (Optional) Log `returns` for done/truncated episodes in W&B\n",
    "    1. [x] Store transition in buffer\n",
    "    1. [x] If enough transitions: Update online network\n",
    "    1. [x] If enough steps: Update target network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a684344-0fec-4994-9062-0dfbe7b1cd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from collections.abc import Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29acfd0d-61c2-4885-a647-5ac3870c33e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a1c1397-dbbf-4e21-a429-7ca08c0e9cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    net: nn.Module,\n",
    "    target_net: nn.Module,\n",
    "    optimizer: optim.Optimizer,\n",
    "    loss_fn,\n",
    "    env,\n",
    "    epsilon_start: float,\n",
    "    epsilon_end: float,\n",
    "    epsilon_decay: int,\n",
    "    gamma: float,\n",
    "    buffer_size: int,\n",
    "    update_batch_size: int,\n",
    "    target_update_steps: int,\n",
    "    n_steps: int,\n",
    "):\n",
    "    assert update_batch_size < buffer_size, \"Buffer must be large enough to hold at least one batch\"\n",
    "    device = next(net.parameters()).device\n",
    "    buffer = ReplayBuffer(capacity=buffer_size)\n",
    "    epsilon = epsilon_start\n",
    "    \n",
    "    obs, _ = env.reset()\n",
    "    obs = obs.copy()\n",
    "    \n",
    "    num_envs = obs.shape[0]\n",
    "    returns = np.zeros([num_envs])\n",
    "    episodes = 0\n",
    "    total_reward = 0\n",
    "\n",
    "    try:\n",
    "        for step in tqdm(range(1, n_steps + 1), desc=\"Steps\"):\n",
    "            with torch.no_grad():\n",
    "                q_values = net(obs)\n",
    "            actions = select_actions(q_values, epsilon)\n",
    "            next_obs, rewards, dones, truncateds, _ = env.step(actions)\n",
    "\n",
    "            if isinstance(obs, Iterable):\n",
    "                # Vectorized Environment\n",
    "                buffer.extend(zip(obs, actions, rewards, next_obs, (dones | truncateds)))\n",
    "                total_reward += sum(rewards)\n",
    "            else:\n",
    "                # Single Environment\n",
    "                buffer.store((obs.copy(), actions.copy(), rewards.copy(), next_obs.copy(), (dones | truncateds).copy()))\n",
    "                total_reward += rewards\n",
    "                if dones:\n",
    "                    next_obs, _ = env.reset()\n",
    "            obs = next_obs.copy()\n",
    "\n",
    "            #if wandb.run is not None:\n",
    "                #wandb.log({\n",
    "                    #\"total_reward\": total_reward,\n",
    "                    #\"epsilon\": epsilon,\n",
    "                #})\n",
    "    \n",
    "            returns += rewards\n",
    "            episodes += np.sum(dones | truncateds)\n",
    "    \n",
    "            done_indices = np.where(dones | truncateds)\n",
    "            if wandb.run is not None and len(returns[done_indices]) > 0:\n",
    "                wandb.log({\n",
    "                    \"avg_return\": np.mean(returns[done_indices]),\n",
    "                    \"epsilon\": epsilon,\n",
    "                })\n",
    "            returns[done_indices] = 0\n",
    "    \n",
    "            if len(buffer) >= update_batch_size:\n",
    "                obs_target, actions_target, rewards_target, next_obs_target, dones_target = zip(*buffer.sample(update_batch_size))\n",
    "                #print(\"Actions:\", actions_target)\n",
    "    \n",
    "                q_target = net(obs_target).gather(1, torch.tensor(actions_target, device=device).unsqueeze(1)).squeeze(1)\n",
    "                #print(\"Qs:\", net(obs_target))\n",
    "                #print(\"Selected Qs:\", q_target)\n",
    "                rewards_t = torch.tensor(rewards_target, device=device)\n",
    "                with torch.no_grad():\n",
    "                    next_q_target = target_net(next_obs_target).max(dim=1).values\n",
    "                    #print(\"Target Qs:\", target_net(next_obs_target))\n",
    "                    #print(\"Rewards:\", rewards_t)\n",
    "                    #print(\"Gamma:\", gamma)\n",
    "                    #print(\"Target max Qs:\", next_q_target)\n",
    "                    dones_t = torch.tensor(dones_target, device=device)\n",
    "                    #print(\"Dones:\", dones_t)\n",
    "                    target = rewards_t + ~dones_t * gamma * next_q_target\n",
    "                    #print(\"Target:\", target)\n",
    "                    \n",
    "                loss = loss_fn(target, q_target)\n",
    "                #print(\"Loss:\", loss.item())\n",
    "\n",
    "                wandb.log({\n",
    "                    \"loss\": loss.item(),\n",
    "                })\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    \n",
    "            if step % target_update_steps == 0:\n",
    "                target_net.load_state_dict(net.state_dict())\n",
    "    \n",
    "            epsilon = epsilon_start + (epsilon_end - epsilon_start) * min(1.0, (step / epsilon_decay))\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Training stopped manually.\")\n",
    "    \n",
    "    if wandb.run is not None:\n",
    "        wandb.unwatch()\n",
    "        wandb.finish()\n",
    "\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273b225d-aec4-4df8-a959-d9f428f4fe45",
   "metadata": {},
   "source": [
    "## Train an agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f023fbf-f2eb-4e57-88e0-94fe949f6f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pufferlib\n",
    "import pufferlib.vector\n",
    "\n",
    "from pufferlib.environments import atari"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e78625-66b8-4ce8-b2b5-607577e3851e",
   "metadata": {},
   "source": [
    "### Experiment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ea1b293-1f21-48b0-907c-db5496f22e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"CartPole\"\n",
    "project = f\"Puffer-{env_name.title()}-DQN\"\n",
    "learning_rate = 3e-2\n",
    "num_envs = 12 * 2\n",
    "epsilon_start = 0.2\n",
    "epsilon_end = 0.01\n",
    "n_steps = int(1e5)\n",
    "epsilon_decay = 5 * n_steps // 10\n",
    "gamma = 1.0\n",
    "buffer_size = int(1e4)\n",
    "update_batch_size = 4\n",
    "target_update_steps = int(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ff53eae-355d-4530-af5f-1525d14c2a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfitti\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/fitti/projects/puffer/wandb/run-20250216_094831-tbfyc5ti</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fitti/Puffer-Cartpole-DQN/runs/tbfyc5ti' target=\"_blank\">balmy-microwave-22</a></strong> to <a href='https://wandb.ai/fitti/Puffer-Cartpole-DQN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fitti/Puffer-Cartpole-DQN' target=\"_blank\">https://wandb.ai/fitti/Puffer-Cartpole-DQN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fitti/Puffer-Cartpole-DQN/runs/tbfyc5ti' target=\"_blank\">https://wandb.ai/fitti/Puffer-Cartpole-DQN/runs/tbfyc5ti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/fitti/Puffer-Cartpole-DQN/runs/tbfyc5ti?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7e96271fad90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=project,\n",
    "    config={\n",
    "        \"lr\": learning_rate,\n",
    "        \"eps_start\": epsilon_start,\n",
    "        \"eps_end\": epsilon_end,\n",
    "        \"eps_decay\": epsilon_decay,\n",
    "        \"gamma\": gamma,\n",
    "        \"buffer_size\": buffer_size,\n",
    "        \"update_batch_size\": update_batch_size,\n",
    "        \"target_update_steps\": target_update_steps,\n",
    "        \"n_steps\": n_steps,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8aecf7b0-afa6-4602-ab9b-720716390916",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-4:\n",
      "Process Process-8:\n",
      "Process Process-1:\n",
      "Process Process-9:\n",
      "Process Process-12:\n",
      "Process Process-2:\n",
      "Process Process-11:\n",
      "Process Process-10:\n",
      "Process Process-3:\n",
      "Process Process-5:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fitti/.conda/envs/puffer/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/fitti/.conda/envs/puffer/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/fitti/.conda/envs/puffer/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/fitti/.conda/envs/puffer/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/fitti/.conda/envs/puffer/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/fitti/.conda/envs/puffer/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/fitti/.conda/envs/puffer/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/fitti/.conda/envs/puffer/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/fitti/.conda/envs/puffer/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/fitti/.conda/envs/puffer/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/fitti/.conda/envs/puffer/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/fitti/.conda/envs/puffer/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/fitti/.conda/envs/puffer/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/fitti/.conda/envs/puffer/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/fitti/.conda/envs/puffer/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/fitti/.conda/envs/puffer/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/fitti/.conda/envs/puffer/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/fitti/.conda/envs/puffer/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/fitti/.conda/envs/puffer/lib/python3.11/site-packages/pufferlib/vector.py\", line 176, in _worker_process\n",
      "    if time.time() - start > 0.5:\n",
      "       ^^^^^^^^^^^\n",
      "  File \"/home/fitti/.conda/envs/puffer/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/fitti/.conda/envs/puffer/lib/python3.11/site-packages/pufferlib/vector.py\", line 176, in _worker_process\n",
      "    if time.time() - start > 0.5:\n",
      "       ^^^^^^^^^^^\n",
      "  File \"/home/fitti/.conda/envs/puffer/lib/python3.11/site-packages/pufferlib/vector.py\", line 176, in _worker_process\n",
      "    if time.time() - start > 0.5:\n",
      "       ^^^^^^^^^^^\n",
      "  File \"/home/fitti/.conda/envs/puffer/lib/python3.11/site-packages/pufferlib/vector.py\", line 176, in _worker_process\n",
      "    if time.time() - start > 0.5:\n",
      "       ^^^^^^^^^^^\n",
      "  File \"/home/fitti/.conda/envs/puffer/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/fitti/.conda/envs/puffer/lib/python3.11/site-packages/pufferlib/vector.py\", line 176, in _worker_process\n",
      "    if time.time() - start > 0.5:\n",
      "       ^^^^^^^^^^^\n",
      "  File \"/home/fitti/.conda/envs/puffer/lib/python3.11/site-packages/pufferlib/vector.py\", line 176, in _worker_process\n",
      "    if time.time() - start > 0.5:\n",
      "       ^^^^^^^^^^^\n",
      "  File \"/home/fitti/.conda/envs/puffer/lib/python3.11/site-packages/pufferlib/vector.py\", line 176, in _worker_process\n",
      "    if time.time() - start > 0.5:\n",
      "       ^^^^^^^^^^^\n",
      "  File \"/home/fitti/.conda/envs/puffer/lib/python3.11/site-packages/pufferlib/vector.py\", line 176, in _worker_process\n",
      "    if time.time() - start > 0.5:\n",
      "       ^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/home/fitti/.conda/envs/puffer/lib/python3.11/site-packages/pufferlib/vector.py\", line 176, in _worker_process\n",
      "    if time.time() - start > 0.5:\n",
      "       ^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/fitti/.conda/envs/puffer/lib/python3.11/site-packages/pufferlib/vector.py\", line 176, in _worker_process\n",
      "    if time.time() - start > 0.5:\n",
      "       ^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Process Process-7:\n",
      "Process Process-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fitti/.conda/envs/puffer/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/fitti/.conda/envs/puffer/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/fitti/.conda/envs/puffer/lib/python3.11/site-packages/pufferlib/vector.py\", line 176, in _worker_process\n",
      "    if time.time() - start > 0.5:\n",
      "       ^^^^^^^^^^^\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "  File \"/home/fitti/.conda/envs/puffer/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/fitti/.conda/envs/puffer/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/fitti/.conda/envs/puffer/lib/python3.11/site-packages/pufferlib/vector.py\", line 176, in _worker_process\n",
      "    if time.time() - start > 0.5:\n",
      "       ^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "from math import ceil\n",
    "from pufferlib.environments import classic_control\n",
    "\n",
    "env_creator = classic_control.env_creator(\"CartPole-v1\")\n",
    "#env_creator = atari.env_creator(env_name)\n",
    "#from pufferlib.ocean.sanity import Squared\n",
    "\n",
    "vecenv = pufferlib.vector.make(\n",
    "    env_creator,\n",
    "    backend=pufferlib.vector.Multiprocessing,\n",
    "    num_envs=num_envs,\n",
    "    num_workers=12,\n",
    ")\n",
    "\n",
    "#env = Squared()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5f4000e6-c27c-45e1-a0ec-7e21c30ac007",
   "metadata": {},
   "source": [
    "from pufferlib.ocean import Pong\n",
    "import gymnasium as gym\n",
    "\n",
    "vecenv = pufferlib.vector.make(\n",
    "    Pong,\n",
    ")\n",
    "\n",
    "vecenv = gym.wrappers.FrameStack(env=vecenv, num_stack=4)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5ae6ad2c-aaa7-49f2-bbaa-6ba014e9da21",
   "metadata": {},
   "source": [
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dae7b809-6873-4065-bf92-01a8b77bd5df",
   "metadata": {},
   "source": [
    "ob, _ = env.reset()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "62adeb01-3c66-45f6-a31c-3b390ca50ea7",
   "metadata": {},
   "source": [
    "ob_shape = ob.shape\n",
    "ob_shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "96faadab-e27c-41c9-b9bb-c30ad2dee095",
   "metadata": {},
   "source": [
    "obs_shape = (1, *ob_shape)\n",
    "obs_shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6af97a27-525d-4657-8c1f-b54ca6e004d9",
   "metadata": {},
   "source": [
    "env = gym.wrappers.FrameStack(env=env, num_stack=1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cb1ebeb6-fa91-4a8a-bdba-5f30f8051f1f",
   "metadata": {},
   "source": [
    "ob, _ = env.reset()\n",
    "ob.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1bd83b83-bb5f-44ec-bbea-b9e2c45986a1",
   "metadata": {},
   "source": [
    "n_input = np.product(env.observation_space.shape)\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "n_input, n_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72354f95-7cff-4232-82f4-c02c3179ccd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, _ = vecenv.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9151289c-3f82-41d6-a3cb-85129300ff02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9cee5d21-d2e5-41d1-be63-700b482e03e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_input = vecenv.single_observation_space.shape[0]\n",
    "n_actions = vecenv.single_action_space.n\n",
    "\n",
    "n_input, n_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0d67b0d-5c3b-49cf-9b9d-a618e89b374a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf4ea0ae-7e49-4d62-9aa6-2478c1a46e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PufferQNetwork(\n",
      "  (mlp): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=4, out_features=128, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=128, out_features=2, bias=True)\n",
      "  )\n",
      ") \n",
      "898\n"
     ]
    }
   ],
   "source": [
    "net = PufferQNetwork(n_input, n_actions).to(device=device)\n",
    "target_net = PufferQNetwork(n_input, n_actions).to(device=device)\n",
    "target_net.load_state_dict(net.state_dict())\n",
    "target_net.eval()\n",
    "print(net, f\"\\n{sum(p.numel() for p in net.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8aca77ec-7049-4b69-af22-42f045351aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if wandb.run is not None:\n",
    "    wandb.watch(net, log=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7d302b0-90dd-44d3-93c9-968ed1be9048",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92a49058-59ad-41c2-b383-9f068ad0a205",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.SmoothL1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a9bf423-ec5c-4eb9-ba0a-f60dd4315590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "180365a288c343928499520920f09185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Steps:   0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training stopped manually.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_return</td><td>▄▂▂▂▃█▁▁▂▂▂▁▄▂▃▂▄▁▃▁▁▂▂▁▃▂▂▃▄▁▁▁▃▂▅▅▃▆▁▁</td></tr><tr><td>epsilon</td><td>██▇▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>loss</td><td>▂▁▁▁▂▁▁▅▁▁▁▁▄▂▃▁▁▁▁▁▂▁▃▂▂▁▁▂▄▁▆▁▃▁▂▁▁█▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_return</td><td>13</td></tr><tr><td>epsilon</td><td>0.19589</td></tr><tr><td>loss</td><td>1.1967</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">balmy-microwave-22</strong> at: <a href='https://wandb.ai/fitti/Puffer-Cartpole-DQN/runs/tbfyc5ti' target=\"_blank\">https://wandb.ai/fitti/Puffer-Cartpole-DQN/runs/tbfyc5ti</a><br> View project at: <a href='https://wandb.ai/fitti/Puffer-Cartpole-DQN' target=\"_blank\">https://wandb.ai/fitti/Puffer-Cartpole-DQN</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250216_094831-tbfyc5ti/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(\n",
    "    net=net,\n",
    "    target_net=target_net,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    env=vecenv,\n",
    "    epsilon_start=epsilon_start,\n",
    "    epsilon_end=epsilon_end,\n",
    "    epsilon_decay=epsilon_decay,\n",
    "    gamma=gamma,\n",
    "    buffer_size=buffer_size,\n",
    "    update_batch_size=update_batch_size,\n",
    "    target_update_steps=target_update_steps,\n",
    "    n_steps=n_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf9da16-f785-4d72-a964-ee39dcdc3b16",
   "metadata": {},
   "source": [
    "## Agent Evaluation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4b7e244b-52b0-438d-987b-fbb9352e9688",
   "metadata": {},
   "source": [
    "# Create Gymnasium Breakout\n",
    "import gymnasium as gym\n",
    "import ale_py\n",
    "env = gym.make(\"ALE/Breakout-v5\", render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d3a1f99f-b948-4c6d-a544-7a8aa616dc40",
   "metadata": {},
   "source": [
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "video_folder = f\"./videos/{project}_{timestamp}\"\n",
    "env = gym.wrappers.RecordVideo(env, video_folder)\n",
    "\n",
    "env = gym.wrappers.GrayScaleObservation(env=env)\n",
    "env = gym.wrappers.ResizeObservation(env=env, shape=(105, 80))\n",
    "env = gym.wrappers.FrameStack(env=env, num_stack=4)\n",
    "\n",
    "ob, _ = env.reset()\n",
    "ob = np.expand_dims(np.array(ob).transpose(2, 0, 1), 0)\n",
    "print(ob.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4b5055b7-a7ea-4055-9de9-ac5e7f49989b",
   "metadata": {},
   "source": [
    "ob, _ = env.reset()\n",
    "ob = np.expand_dims(np.array(ob).transpose(2, 0, 1), 0)\n",
    "\n",
    "epsilon = epsilon_end\n",
    "ret = 0\n",
    "done, truncated = False, False\n",
    "while not (done or truncated):\n",
    "    with torch.no_grad():\n",
    "        q_values = q_net(ob)\n",
    "    actions = select_actions(q_values, epsilon)\n",
    "    ob, reward, done, truncated, _ = env.step(actions[0])\n",
    "    ob = np.expand_dims(np.array(ob).transpose(2, 0, 1), 0)\n",
    "    ret += reward\n",
    "\n",
    "print(ret)\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
